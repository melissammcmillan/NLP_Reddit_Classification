{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook 3: Getting Started on Modelling with Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will experiment with preprocessing tools and hyperparameter tuning to try to acheive the best Naive Bayes Classifier model that can discern which subreddit page a submission title corresponds to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick note about this notebook: it contains ALOT of models, like 15 of them. I like to be intentional about each model and tweak one variable at a time to get a good feel for how one model compares to the next. If you don't want to look through all of the models, please go down to Model 4 (Pipe4/GS4) and check that one out- it turned out to be the best model in this notebook. It utilized the custom Lemmatizer with TfidfVectorizer, which gave me a test score of ~93%. It also had the best Recall/Sensitivity score of .89 and lowest false negative value of 11%. I tested many more models after this one, but used this one as best and then moved on to the next notebook (Notebook 04) after realizing below that I had further cleaning to do to my data as a result of the modelling here. So, if you like, you can move on to Notebook 04 to see my final Naive Bayes models, or scroll down below to follow my modelling process from the very beginning. Enjoy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Imports and my model evaluation functions to make life easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(pipe, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"function for evaluating a model inside of a pipeline.\"\"\"\n",
    "#     y_train_preds = pipe.predict(X_train)\n",
    "#     rmse_train = mean_squared_error(y_train, y_train_preds, squared=False)\n",
    "    y_test_preds = pipe.predict(X_test)\n",
    "    print(f'Your train score is: {cross_val_score(pipe, X_train, y_train)}')\n",
    "    print(f'Your mean train score is: {np.mean(cross_val_score(pipe, X_train, y_train))}')\n",
    "    print(f'Your test score is: {cross_val_score(pipe, X_test, y_test)}')\n",
    "    print(f'Your mean test score is: {np.mean(cross_val_score(pipe, X_test, y_test))}')\n",
    "    print(f'Your test recall/sensitivity score is: {recall_score(y_test, y_test_preds)}')\n",
    "    print(f'Your confusion matrix is: {confusion_matrix(y_test, y_test_preds, normalize = \"true\")}')\n",
    "#    plot_confusion_matrix(logreg, X_test, y_test, display_labels=['alive', 'dead'])\n",
    "#     plot_roc_curve(logreg, X_test, y_test);\n",
    "#     print(f'Your train RMSE is: {rmse_train}')\n",
    "#     print(f'Your test RMSE is: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_coefs(pipe, vectorizer):\n",
    "    \"\"\" This function will give you a dataframe with your features and their coefficients/importances so you can sort them\"\"\"\n",
    "    features = pipe.named_steps[vectorizer].get_feature_names()\n",
    "    coefficients = pipe.named_steps['multinomialnb'].coef_\n",
    "    flattened_coefs = [val for sublist in coefficients for val in sublist]\n",
    "    pipe_coefs_df = pd.DataFrame({'coefs': flattened_coefs, 'names': features})\n",
    "    return pipe_coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_gs(gs, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"function to get the model results when using GridSearchCV\"\"\"\n",
    "#     y_train_preds = gs.predict(X_train)\n",
    "#     rmse_train = mean_squared_error(y_train, y_train_preds, squared=False)\n",
    "    y_test_preds = gs.predict(X_test)\n",
    "#     rmse_test = mean_squared_error(y_test, y_test_preds, squared=False)\n",
    "    print(f'Your train score is: {gs.score(X_train, y_train)}')\n",
    "    print(f'Your test score is: {gs.score(X_test, y_test)}')\n",
    "    print(f'Your best test params were: {gs.best_params_}')\n",
    "    print(f'Your test recall/sensitivity score is: {recall_score(y_test, y_test_preds)}')\n",
    "    print(f'Your confusion matrix is: {confusion_matrix(y_test, y_test_preds, normalize = \"true\")}')\n",
    "#     print(f'Your train RMSE is: {rmse_train}')\n",
    "#     print(f'Your test RMSE is: {rmse_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coefs_gs(gs, vectorizer):\n",
    "    \"\"\"function to get the coefficients when using GridSearchCV\"\"\"\n",
    "    coefs = gs.best_estimator_.named_steps['multinomialnb'].coef_\n",
    "    flattened_coefs = [val for sublist in coefs for val in sublist]\n",
    "    feats = gs.best_estimator_.named_steps[vectorizer].get_feature_names()\n",
    "    gs_coef_df = pd.DataFrame({'coefs': flattened_coefs, 'names': feats})\n",
    "    return gs_coef_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Read in the combined dataset I saved in Notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = pd.read_csv('./data/combined_data_with_selftext.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Some genius explains how the Trump riots is ‚ÄòG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jagjeet Sandhu Age, Career, Personal Life- Bio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaagaz: plot, cast, review. Kaagaz is a 2021 I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Urvi Singh Age, Career, Personal Life- Biograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gameofthrones</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abhishek Banerjee: Wiki, age, birthday &amp;amp; f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>lotr</td>\n",
       "      <td>I read the lotr for the first time a few month...</td>\n",
       "      <td>lotr is calling me back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10196</th>\n",
       "      <td>lotr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fly, you fools!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10197</th>\n",
       "      <td>lotr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cool fire pit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>lotr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Who remembers when LOTR first premiered?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10199</th>\n",
       "      <td>lotr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lotr inspired pumpkin I carved for Halloween.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10200 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit                                           selftext  \\\n",
       "0      gameofthrones                                                NaN   \n",
       "1      gameofthrones                                                NaN   \n",
       "2      gameofthrones                                                NaN   \n",
       "3      gameofthrones                                                NaN   \n",
       "4      gameofthrones                                                NaN   \n",
       "...              ...                                                ...   \n",
       "10195           lotr  I read the lotr for the first time a few month...   \n",
       "10196           lotr                                                NaN   \n",
       "10197           lotr                                                NaN   \n",
       "10198           lotr                                                NaN   \n",
       "10199           lotr                                                NaN   \n",
       "\n",
       "                                                   title  \n",
       "0      Some genius explains how the Trump riots is ‚ÄòG...  \n",
       "1      Jagjeet Sandhu Age, Career, Personal Life- Bio...  \n",
       "2      Kaagaz: plot, cast, review. Kaagaz is a 2021 I...  \n",
       "3      Urvi Singh Age, Career, Personal Life- Biograp...  \n",
       "4      Abhishek Banerjee: Wiki, age, birthday &amp; f...  \n",
       "...                                                  ...  \n",
       "10195                            lotr is calling me back  \n",
       "10196                                    Fly, you fools!  \n",
       "10197                                      Cool fire pit  \n",
       "10198           Who remembers when LOTR first premiered?  \n",
       "10199      Lotr inspired pumpkin I carved for Halloween.  \n",
       "\n",
       "[10200 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will drop the 'selftext' column so we can just model using the submission titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_titles.drop('selftext', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin my modelling with Naive Bayes, my plan of attack is to first run a null model for comparison, then run a first-pass simple model using CountVectorizer with stop words (since we learned that would probably be helpful in Notebook 2), Standard Scaler, and Naive Bayes. After those first two steps, I will add complexity and use GridSearch to optimize hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, I'm using accuracy score, recall/sensitivity score, and the confusion matrix to evaluate my models. The accuracy score will be assessed on both the train and test sets, and I'll be keeping an eye out for overfitting (when train score is much higher than test score). The Recall/Sensitivity score will give me an estimate of which model optimizes the True Positive Rate best (how well I'm doing at getting the best True Positive Predictions and minimizing the False Negative Predictions). I'm also going to be looking at the lower left value of a confusion matrix after each model, as that will give me the False Negative value, which I want to be as low as possible. I would rather my friend let in some Lord of the Rings posts rather than filter out some legit Game of Thrones posts, so I'm looking to reduce the False Negative score as much as positive (remember that LOTR is 0, so getting that prediction wrong would be a false negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Step: Set up my X and Y and split into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_titles['title']\n",
    "y = all_titles['subreddit'].map({'gameofthrones': 1, 'lotr': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7650,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7650,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second Step: Make a null model using DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.fit(X_train, y_train)\n",
    "y_dummy_preds = dc.predict(X_test)\n",
    "y_dummy_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#My dummy predictions are ready for when we run our first simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third Step: Run a first-pass simple model and evaluate initial scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(CountVectorizer(stop_words='english'), StandardScaler(with_mean=False), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer(stop_words='english')),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.88235294 0.85686275 0.86078431 0.87320261 0.84836601]\n",
      "Your mean train score is: 0.864313725490196\n",
      "Your test score is: [0.84117647 0.85882353 0.86666667 0.84313725 0.83921569]\n",
      "Your mean test score is: 0.8498039215686275\n",
      "Your test recall/sensitivity score is: 0.8592\n",
      "Your confusion matrix is: [[0.87   0.13  ]\n",
      " [0.1408 0.8592]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe1, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48745098039215684"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.score(X_test, y_dummy_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial model assessment: scores are starting out pretty high. It looks like I might have some overfitting going on because my train score is a little higher than my test score, but overall I think I'm seeing some initial success. Also, I would expect my null model to be around 50% accuracy, since I have an equal number of titles from both classes. So a dummy score of ~50% makes sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will move onto my Step Three: Making a GridSearchCV to test more CountVectorizer parameters and experiment with alpha values in the Naive Bayes algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(CountVectorizer(), StandardScaler(with_mean=False), MultinomialNB())\n",
    "params2 = {'countvectorizer__stop_words': [None, 'english'],\n",
    "          'countvectorizer__max_features': [None, 250, 500],\n",
    "          'countvectorizer__ngram_range': [(1,1),(1,3)],\n",
    "          'multinomialnb__alpha': [0, 0.00001, 0.5, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2 = GridSearchCV(pipe2, param_grid=params2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                                       ('standardscaler',\n",
       "                                        StandardScaler(with_mean=False)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'countvectorizer__max_features': [None, 250, 500],\n",
       "                         'countvectorizer__ngram_range': [(1, 1), (1, 3)],\n",
       "                         'countvectorizer__stop_words': [None, 'english'],\n",
       "                         'multinomialnb__alpha': [0, 1e-05, 0.5, 1.0]})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: 0.9959477124183006\n",
      "Your test score is: 0.903921568627451\n",
      "Your best test params were: {'countvectorizer__max_features': None, 'countvectorizer__ngram_range': (1, 3), 'countvectorizer__stop_words': None, 'multinomialnb__alpha': 1.0}\n",
      "Your test recall/sensitivity score is: 0.9112\n",
      "Your confusion matrix is: [[0.89692308 0.10307692]\n",
      " [0.0888     0.9112    ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model_gs(gs2, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, pretty good recall score and very low false negative score of .088."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-12.014657</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-15.542960</td>\n",
       "      <td>00 00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-15.542960</td>\n",
       "      <td>00 00 you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.542960</td>\n",
       "      <td>00 cad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-15.542960</td>\n",
       "      <td>00 cad on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95673</th>\n",
       "      <td>-11.060297</td>\n",
       "      <td>ùêèùêÇ 2gb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95674</th>\n",
       "      <td>-11.060297</td>\n",
       "      <td>ùêèùêÇ 2gb ram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95675</th>\n",
       "      <td>-11.060297</td>\n",
       "      <td>ùüêùüéùüïùüï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95676</th>\n",
       "      <td>-11.060297</td>\n",
       "      <td>ùüêùüéùüïùüï in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95677</th>\n",
       "      <td>-11.060297</td>\n",
       "      <td>ùüêùüéùüïùüï in ùêãùê®ùê∞</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95678 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           coefs        names\n",
       "0     -12.014657           00\n",
       "1     -15.542960        00 00\n",
       "2     -15.542960    00 00 you\n",
       "3     -15.542960       00 cad\n",
       "4     -15.542960    00 cad on\n",
       "...          ...          ...\n",
       "95673 -11.060297       ùêèùêÇ 2gb\n",
       "95674 -11.060297   ùêèùêÇ 2gb ram\n",
       "95675 -11.060297         ùüêùüéùüïùüï\n",
       "95676 -11.060297      ùüêùüéùüïùüï in\n",
       "95677 -11.060297  ùüêùüéùüïùüï in ùêãùê®ùê∞\n",
       "\n",
       "[95678 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2_coefs = get_coefs_gs(gs2, 'countvectorizer')\n",
    "gs2_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70145</th>\n",
       "      <td>-7.499172</td>\n",
       "      <td>spoilers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74476</th>\n",
       "      <td>-7.630729</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52122</th>\n",
       "      <td>-7.773456</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>-7.787469</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52241</th>\n",
       "      <td>-7.798127</td>\n",
       "      <td>no spoilers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-7.855833</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38983</th>\n",
       "      <td>-7.885475</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11436</th>\n",
       "      <td>-7.890171</td>\n",
       "      <td>bigg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12500</th>\n",
       "      <td>-7.913962</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11439</th>\n",
       "      <td>-7.914966</td>\n",
       "      <td>bigg boss</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          coefs        names\n",
       "70145 -7.499172     spoilers\n",
       "74476 -7.630729          the\n",
       "52122 -7.773456           no\n",
       "4890  -7.787469          and\n",
       "52241 -7.798127  no spoilers\n",
       "216   -7.855833           14\n",
       "38983 -7.885475           is\n",
       "11436 -7.890171         bigg\n",
       "12500 -7.913962         boss\n",
       "11439 -7.914966    bigg boss"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs2_coefs.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well my scores improved, but I'm still a little overfit. There is a delta of ~7-8% between my train set and my test set. My best model did not utilize the stop words parameter, no max feature limits, and an ngram range of (1,3) in the count vectorizer, and the Naive Bayes algorithm preferred the default alpha value of 1.0. This is good to know! I think next model I'd like to run will utilize a Tokenizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief recap on what each of these NLP terms are because I want to make sure I understand what I'm doing. So, a Tokenizer takes in a string and breaks it up according to a pattern, and different tokenizers have their own unique algorthim to identify patterns (for example a sentence tokenizer vs a word tokenizer, each are different patterns). A vectorizer splits the text string up such that each word (or combo of words if using ngrams) is a vector, which can then be used for modelling. The CountVectorizer works differently than a Tfidf Vectorizer, although we can use a tokenizer in both and both vectorizers utilize similar hyperparameters. The CountVector simply vectorizes based on the words, whereas the Tfidf Vectorizer assigns a score based on which words (or ngram group of words) appear less frequently (but importantly) across all of our \"documents\". The words (or combination of words) that appear often in one document vs another get more importance, or predictive power, because they make some documents unique relative to the others. Finally, it is sometimes useful to use a tokenizer inside of a vectorizer, because pre-emptively splitting up words that belong to a pattern can help optimize the vectorizer's separation of the words. Plus, tokenizers can help ensure we are removing useless word items like symbols, or keeping money-related strings together, before passing them into a vectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a custom class\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.lemmatizer.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2b = make_pipeline(CountVectorizer(tokenizer = LemmaTokenizer()), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f8906c19850>)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2b.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.9124183  0.91568627 0.93398693 0.91895425 0.90784314]\n",
      "Your mean train score is: 0.9177777777777777\n",
      "Your test score is: [0.91372549 0.91764706 0.91568627 0.90980392 0.90588235]\n",
      "Your mean test score is: 0.9125490196078431\n",
      "Your test recall/sensitivity score is: 0.8472\n",
      "Your confusion matrix is: [[0.97461538 0.02538462]\n",
      " [0.1528     0.8472    ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe2b, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that although my overall scores are lower, I have reduced the overfitting problem quite a bit, so that is good. A ~92% test score is pretty decent, I would say."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(CountVectorizer(tokenizer = LemmaTokenizer()), StandardScaler(with_mean=False), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f891ffdd1f0>)),\n",
       "                ('standardscaler', StandardScaler(with_mean=False)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.89215686 0.86470588 0.87908497 0.87843137 0.86666667]\n",
      "Your mean train score is: 0.8762091503267975\n",
      "Your test score is: [0.84901961 0.85294118 0.85490196 0.82941176 0.84313725]\n",
      "Your mean test score is: 0.8458823529411765\n",
      "Your test recall/sensitivity score is: 0.852\n",
      "Your confusion matrix is: [[0.90769231 0.09230769]\n",
      " [0.148      0.852     ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe3, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting observation: I just noticed that if I add in StandardScaler, my results become overfit again. Interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I would like to try a similar pipeline using Tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe4 = make_pipeline(TfidfVectorizer(tokenizer = LemmaTokenizer()), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_4= {'tfidfvectorizer__stop_words': [None, 'english'],\n",
    "         'tfidfvectorizer__max_features': [None, 500, 1000],\n",
    "         'multinomialnb__alpha': [0, 0.00001, 0.5, 1.0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs4 = GridSearchCV(pipe4, param_grid=params_4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                        TfidfVectorizer(tokenizer=<__main__.LemmaTokenizer object at 0x7f8919d90550>)),\n",
       "                                       ('multinomialnb', MultinomialNB())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'multinomialnb__alpha': [0, 1e-05, 0.5, 1.0],\n",
       "                         'tfidfvectorizer__max_features': [None, 500, 1000],\n",
       "                         'tfidfvectorizer__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: 0.9626143790849673\n",
      "Your test score is: 0.9243137254901961\n",
      "Your best test params were: {'multinomialnb__alpha': 1.0, 'tfidfvectorizer__max_features': None, 'tfidfvectorizer__stop_words': 'english'}\n",
      "Your test recall/sensitivity score is: 0.8928\n",
      "Your confusion matrix is: [[0.95461538 0.04538462]\n",
      " [0.1072     0.8928    ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model_gs(gs4, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, this is interesting. I still have a bit of overfitting with this model, and the TfidfVectorizer wanted to utilize the stop words parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.810685</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.173463</td>\n",
       "      <td>#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-8.706905</td>\n",
       "      <td>$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.988022</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.674939</td>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9149</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>üßôüèª‚Äç‚ôÇÔ∏èüßùüèº‚Äç‚ôÇÔ∏èüßôüèª‚Äç‚ôÄÔ∏èüßùüèª‚Äç‚ôÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9150</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>üßù‚Äç‚ôÄÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9151</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>üßù‚Äç‚ôÇÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9152</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>üßùüèª‚Äç‚ôÇÔ∏è</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9153</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>üß≠</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9154 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs                 names\n",
       "0    -5.810685                     !\n",
       "1    -8.173463                     #\n",
       "2    -8.706905                     $\n",
       "3    -8.988022                     %\n",
       "4    -6.674939                     &\n",
       "...        ...                   ...\n",
       "9149 -9.977482  üßôüèª‚Äç‚ôÇÔ∏èüßùüèº‚Äç‚ôÇÔ∏èüßôüèª‚Äç‚ôÄÔ∏èüßùüèª‚Äç‚ôÄÔ∏è\n",
       "9150 -9.977482                  üßù‚Äç‚ôÄÔ∏è\n",
       "9151 -9.977482                  üßù‚Äç‚ôÇÔ∏è\n",
       "9152 -9.977482                 üßùüèª‚Äç‚ôÇÔ∏è\n",
       "9153 -9.977482                     üß≠\n",
       "\n",
       "[9154 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_coefs = get_coefs_gs(gs4, 'tfidfvectorizer')\n",
    "gs4_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-9.627042</td>\n",
       "      <td>'jealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-9.622338</td>\n",
       "      <td>'kaleshi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-9.565730</td>\n",
       "      <td>'light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-8.995924</td>\n",
       "      <td>'ll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>'lord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-8.238271</td>\n",
       "      <td>'m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-9.033606</td>\n",
       "      <td>'main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-9.781624</td>\n",
       "      <td>'mera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>'mountains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>'only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-9.726469</td>\n",
       "      <td>'pavitra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>'potential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-9.605365</td>\n",
       "      <td>'re</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-9.507144</td>\n",
       "      <td>'red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-6.091130</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-9.430508</td>\n",
       "      <td>'saand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-9.478782</td>\n",
       "      <td>'sarpanch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-9.977482</td>\n",
       "      <td>'shire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-9.476598</td>\n",
       "      <td>'tharki'nikki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-9.643358</td>\n",
       "      <td>'the</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       coefs          names\n",
       "30 -9.627042       'jealous\n",
       "31 -9.622338       'kaleshi\n",
       "32 -9.565730         'light\n",
       "33 -8.995924            'll\n",
       "34 -9.977482          'lord\n",
       "35 -8.238271             'm\n",
       "36 -9.033606          'main\n",
       "37 -9.781624          'mera\n",
       "38 -9.977482     'mountains\n",
       "39 -9.977482          'only\n",
       "40 -9.726469       'pavitra\n",
       "41 -9.977482     'potential\n",
       "42 -9.605365            're\n",
       "43 -9.507144           'red\n",
       "44 -6.091130             's\n",
       "45 -9.430508         'saand\n",
       "46 -9.478782      'sarpanch\n",
       "47 -9.977482         'shire\n",
       "48 -9.476598  'tharki'nikki\n",
       "49 -9.643358           'the"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_coefs.iloc[30:50,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'üß≠'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_coefs.iloc[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gs4_coefs.iloc[-1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>-4.480256</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-4.560347</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>-4.561278</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-4.765667</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-4.890906</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-4.938346</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-5.154512</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2520</th>\n",
       "      <td>-5.169738</td>\n",
       "      <td>episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>-5.297313</td>\n",
       "      <td>roadies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5801</th>\n",
       "      <td>-5.331101</td>\n",
       "      <td>revolution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs       names\n",
       "6538 -4.480256     spoiler\n",
       "403  -4.560347           ]\n",
       "401  -4.561278           [\n",
       "67   -4.765667           ,\n",
       "395  -4.890906           :\n",
       "79   -4.938346         ...\n",
       "77   -5.154512           .\n",
       "2520 -5.169738     episode\n",
       "5858 -5.297313     roadies\n",
       "5801 -5.331101  revolution"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_coefs.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! I clearly need to get some of these symbols and emojies out of my models! I'm going to try to do that by utilizing max_features for both the CountVectorizer and Tfidf model scenarios. We'll see if that strategy improves my modelling at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5 = make_pipeline(CountVectorizer(tokenizer = LemmaTokenizer(), lowercase=True, stop_words='english', max_features = 1_000), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(max_features=1000, stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f8920159760>)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.89869281 0.90784314 0.91372549 0.89542484 0.89411765]\n",
      "Your mean train score is: 0.9019607843137255\n",
      "Your test score is: [0.90588235 0.90980392 0.90588235 0.9        0.89803922]\n",
      "Your mean test score is: 0.903921568627451\n",
      "Your test recall/sensitivity score is: 0.8488\n",
      "Your confusion matrix is: [[0.93076923 0.06923077]\n",
      " [0.1512     0.8488    ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe5, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe5_coefs_df = pipe_coefs(pipe5, 'countvectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.030385</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-3.277778</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-3.290517</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.579315</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-3.689315</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-3.749214</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-3.750979</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-4.037484</td>\n",
       "      <td>bigg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>-4.086921</td>\n",
       "      <td>bos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-4.114492</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs    names\n",
       "14  -3.030385        ,\n",
       "18  -3.277778      ...\n",
       "59  -3.290517        :\n",
       "16  -3.579315        .\n",
       "751 -3.689315  spoiler\n",
       "64  -3.749214        [\n",
       "65  -3.750979        ]\n",
       "144 -4.037484     bigg\n",
       "159 -4.086921      bos\n",
       "28  -4.114492       14"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5_coefs_df.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>aragorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>arwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>audiobook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>balrog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>bilbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>blu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-10.78272</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs        names\n",
       "77  -10.78272        added\n",
       "95  -10.78272  anniversary\n",
       "102 -10.78272      aragorn\n",
       "110 -10.78272        arwen\n",
       "116 -10.78272    audiobook\n",
       "128 -10.78272       balrog\n",
       "145 -10.78272        bilbo\n",
       "151 -10.78272   blockchain\n",
       "152 -10.78272          blu\n",
       "154 -10.78272         blue"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe5_coefs_df.nsmallest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6 = make_pipeline(CountVectorizer(tokenizer = LemmaTokenizer(), lowercase=True, stop_words='english', max_features = 500), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(max_features=500, stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f891a7436d0>)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.88300654 0.89019608 0.89346405 0.87777778 0.87254902]\n",
      "Your mean train score is: 0.8833986928104576\n",
      "Your test score is: [0.89411765 0.90980392 0.90392157 0.89607843 0.90392157]\n",
      "Your mean test score is: 0.9015686274509804\n",
      "Your test recall/sensitivity score is: 0.856\n",
      "Your confusion matrix is: [[0.89846154 0.10153846]\n",
      " [0.144      0.856     ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe6, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6_coefs_df = pipe_coefs(pipe6, 'countvectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-2.918316</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.165710</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-3.178449</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-3.467246</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>-3.577247</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-3.637145</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-3.638910</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-3.925415</td>\n",
       "      <td>bigg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-3.974853</td>\n",
       "      <td>bos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-4.002423</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs    names\n",
       "11  -2.918316        ,\n",
       "15  -3.165710      ...\n",
       "39  -3.178449        :\n",
       "13  -3.467246        .\n",
       "379 -3.577247  spoiler\n",
       "43  -3.637145        [\n",
       "44  -3.638910        ]\n",
       "82  -3.925415     bigg\n",
       "91  -3.974853      bos\n",
       "20  -4.002423       14"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe6_coefs_df.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>aragorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>bilbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>elf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>elvish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>fellowship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>galadriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>gandalf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-10.670652</td>\n",
       "      <td>gollum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs       names\n",
       "61  -10.670652     aragorn\n",
       "83  -10.670652       bilbo\n",
       "87  -10.670652  blockchain\n",
       "154 -10.670652         elf\n",
       "156 -10.670652      elvish\n",
       "176 -10.670652  fellowship\n",
       "184 -10.670652       frodo\n",
       "187 -10.670652   galadriel\n",
       "189 -10.670652     gandalf\n",
       "194 -10.670652      gollum"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe6_coefs_df.nsmallest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe7 = make_pipeline(TfidfVectorizer(tokenizer = LemmaTokenizer(), lowercase=True, stop_words='english', max_features = 1_000), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_features=1000, stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f891ed2d730>)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe7.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.90849673 0.91503268 0.92156863 0.90718954 0.90522876]\n",
      "Your mean train score is: 0.9115032679738562\n",
      "Your test score is: [0.91960784 0.91960784 0.90980392 0.90588235 0.90196078]\n",
      "Your mean test score is: 0.9113725490196078\n",
      "Your test recall/sensitivity score is: 0.872\n",
      "Your confusion matrix is: [[0.92538462 0.07461538]\n",
      " [0.128      0.872     ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe7, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe7_coefs_df = pipe_coefs(pipe7, 'tfidfvectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-3.578532</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-3.644315</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-3.644775</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-3.947578</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-4.083258</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-4.129737</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-4.314560</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-4.509051</td>\n",
       "      <td>episode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-4.515464</td>\n",
       "      <td>bigg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>-4.523469</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs    names\n",
       "751 -3.578532  spoiler\n",
       "65  -3.644315        ]\n",
       "64  -3.644775        [\n",
       "14  -3.947578        ,\n",
       "59  -4.083258        :\n",
       "18  -4.129737      ...\n",
       "16  -4.314560        .\n",
       "297 -4.509051  episode\n",
       "144 -4.515464     bigg\n",
       "62  -4.523469        ?"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe7_coefs_df.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>added</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>anniversary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>aragorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>arwen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>audiobook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>balrog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>bilbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>blu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-9.387544</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs        names\n",
       "77  -9.387544        added\n",
       "95  -9.387544  anniversary\n",
       "102 -9.387544      aragorn\n",
       "110 -9.387544        arwen\n",
       "116 -9.387544    audiobook\n",
       "128 -9.387544       balrog\n",
       "145 -9.387544        bilbo\n",
       "151 -9.387544   blockchain\n",
       "152 -9.387544          blu\n",
       "154 -9.387544         blue"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe7_coefs_df.nsmallest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe8 = make_pipeline(TfidfVectorizer(tokenizer = LemmaTokenizer(), lowercase=True, stop_words='english', max_features = 500), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer',\n",
       "                 TfidfVectorizer(max_features=500, stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f8906253d60>)),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe8.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your train score is: [0.8875817  0.89869281 0.90392157 0.88431373 0.88039216]\n",
      "Your mean train score is: 0.8909803921568628\n",
      "Your test score is: [0.89215686 0.91176471 0.90980392 0.90588235 0.90196078]\n",
      "Your mean test score is: 0.9043137254901961\n",
      "Your test recall/sensitivity score is: 0.876\n",
      "Your confusion matrix is: [[0.89461538 0.10538462]\n",
      " [0.124      0.876     ]]\n"
     ]
    }
   ],
   "source": [
    "eval_model(pipe8, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe8_coefs_df = pipe_coefs(pipe8, 'tfidfvectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>-3.363346</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-3.425938</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-3.427465</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-3.722264</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-3.883598</td>\n",
       "      <td>:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-3.919770</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.059590</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-4.311691</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>-4.328895</td>\n",
       "      <td>bigg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-4.366611</td>\n",
       "      <td>bos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs    names\n",
       "379 -3.363346  spoiler\n",
       "44  -3.425938        ]\n",
       "43  -3.427465        [\n",
       "11  -3.722264        ,\n",
       "39  -3.883598        :\n",
       "15  -3.919770      ...\n",
       "13  -4.059590        .\n",
       "42  -4.311691        ?\n",
       "82  -4.328895     bigg\n",
       "91  -4.366611      bos"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe8_coefs_df.nlargest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>aragorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>bilbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>blockchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>elf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>elvish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>fellowship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>frodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>galadriel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>gandalf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-9.297688</td>\n",
       "      <td>gollum</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        coefs       names\n",
       "61  -9.297688     aragorn\n",
       "83  -9.297688       bilbo\n",
       "87  -9.297688  blockchain\n",
       "154 -9.297688         elf\n",
       "156 -9.297688      elvish\n",
       "176 -9.297688  fellowship\n",
       "184 -9.297688       frodo\n",
       "187 -9.297688   galadriel\n",
       "189 -9.297688     gandalf\n",
       "194 -9.297688      gollum"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe8_coefs_df.nsmallest(10, 'coefs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, I think I have completed my first/initial round of modelling using Multinomial Naive Bayes. My best model was number 4, utilizing the custom Lemmatizer with TfidfVectorizer, which gave me a test score of ~93%. It also had the best Recall/Sensitivity score of .89 and lowest false negative value of 11%. I'm fairly happy with that, but I wonder if cleaning the data of the symbols and emojis will give me a better result. I'm going to make a nice plot of this model's largest/most important features for my presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>-4.480256</td>\n",
       "      <td>spoiler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-4.560347</td>\n",
       "      <td>]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs    names\n",
       "6538 -4.480256  spoiler\n",
       "403  -4.560347        ]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_top_words = gs4_coefs.nlargest(10, 'coefs')\n",
    "gs4_top_words.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs4_top_words2 = gs4_top_words.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coefs</th>\n",
       "      <th>names</th>\n",
       "      <th>coefs_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6538</th>\n",
       "      <td>-4.480256</td>\n",
       "      <td>spoiler</td>\n",
       "      <td>4.480256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-4.560347</td>\n",
       "      <td>]</td>\n",
       "      <td>4.560347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         coefs    names  coefs_abs\n",
       "6538 -4.480256  spoiler   4.480256\n",
       "403  -4.560347        ]   4.560347"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs4_top_words2['coefs_abs']  = np.absolute(gs4_top_words2['coefs'])\n",
    "gs4_top_words2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs4_top_words2 = gs4_top_words2.drop('coefs', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, fig = plt.subplots(figsize = (13, 8))\n",
    "\n",
    "sns.barplot(x=\"names\", y=\"coefs_abs\", data=gs4_top_words2, palette = 'crest')\n",
    "\n",
    "plt.title('10 Most Important Words in Best Naive Bayes Model');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, what have I learned here? The CountVectorizer and TfidfVectorizer are giving me very similar results when I test the similar hyperparameters. I don't see a need to use StandardScaler here, so I won't continue using it. Additionally, I was able to eliminate the emojis from my features by limiting the max_features, but I still have quite a few symbols in my features so I need to get rid of those next. I am going to go back to my EDA notebook and eliminate those features from my dataset and save it out, so they are just gone from my modelling moving forward. I may also start a new Naive Bayes modelling notebook so that I can continue modelling after what I've learned here, and then experiment with n_gram range as my next feature to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
